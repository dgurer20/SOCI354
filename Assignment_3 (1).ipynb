{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b77a102-69e5-4f77-bf19-7820a57f43ef",
   "metadata": {},
   "source": [
    "QUESTION 1\n",
    "To scrape, I chose https://books.toscrape.com/ which is verified that it is permissible to scrape it ( actually, the website is a demo website for learners to learn web scraping so I chose that). The website comprises of information about books, and details regarding their prices, reviews, and other information. The data I will extract will contain book names, reviews, availabiltiy and prices of books. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6a4c6e-4605-49d5-a847-757e51cca18b",
   "metadata": {},
   "source": [
    "QUESTION 2\n",
    "I already had the necessary python library which is Scrapy as chosen in this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e68de208-8b9f-4b93-9b62-9edf2f1cf307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: Twisted>=18.9.0 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (22.10.0)\n",
      "Requirement already satisfied: cryptography>=3.4.6 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (41.0.3)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (1.0.4)\n",
      "Requirement already satisfied: parsel>=1.5.0 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (1.6.0)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (23.2.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (1.5.0)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (18.1.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (1.21.0)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (5.4.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (0.1.16)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (0.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (68.0.0)\n",
      "Requirement already satisfied: packaging in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (23.1)\n",
      "Requirement already satisfied: tldextract in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (3.2.0)\n",
      "Requirement already satisfied: lxml>=4.3.0 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (4.9.3)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from scrapy) (2.0.5)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from cryptography>=3.4.6->scrapy) (1.15.1)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from itemloaders>=1.0.1->scrapy) (0.10.0)\n",
      "Requirement already satisfied: six>=1.6.0 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from parsel>=1.5.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: attrs>=16.0.0 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from service-identity>=18.1.0->scrapy) (22.1.0)\n",
      "Requirement already satisfied: pyasn1-modules in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: pyasn1 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: constantly>=15.1 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from Twisted>=18.9.0->scrapy) (15.1.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from Twisted>=18.9.0->scrapy) (21.3.0)\n",
      "Requirement already satisfied: Automat>=0.8.0 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from Twisted>=18.9.0->scrapy) (20.2.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from Twisted>=18.9.0->scrapy) (4.7.1)\n",
      "Requirement already satisfied: idna in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from tldextract->scrapy) (3.4)\n",
      "Requirement already satisfied: requests>=2.1.0 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from tldextract->scrapy) (2.31.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from tldextract->scrapy) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from tldextract->scrapy) (3.9.0)\n",
      "Requirement already satisfied: pycparser in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.4.6->scrapy) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from requests>=2.1.0->tldextract->scrapy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from requests>=2.1.0->tldextract->scrapy) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scrapy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe9d0665-b8b7-44aa-888c-1d23ca44a454",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from requests) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8001ec7a-cdae-4fde-856d-635c06d1dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22120e0b-5f23-41c6-aa3a-839ea941dbbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items:  541\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scrapy import Selector  #looked it up from the \"crapy: extracting real estate data from emlakjet\" course notes for this code\n",
    "\n",
    "import requests\n",
    "\n",
    "url = 'https://books.toscrape.com/'\n",
    "\n",
    "html = requests.get(url).content\n",
    "\n",
    "\n",
    "sel = Selector(text = html)\n",
    "\n",
    "\n",
    "print( \"number of items: \", len(sel.xpath('//*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d14781b-7d54-497b-b74f-47dab5a3d683",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book Price:\n",
      "£51.77\n",
      "£53.74\n",
      "£50.10\n",
      "£47.82\n",
      "£54.23\n",
      "£22.65\n",
      "£33.34\n",
      "£17.93\n",
      "£22.60\n",
      "£52.15\n",
      "£13.99\n",
      "£20.66\n",
      "£17.46\n",
      "£52.29\n",
      "£35.02\n",
      "£57.25\n",
      "£23.88\n",
      "£37.59\n",
      "£51.33\n",
      "£45.17\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scrapy import Selector  \n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "url = 'https://books.toscrape.com/'\n",
    "\n",
    "\n",
    "html = requests.get(url).content\n",
    "\n",
    "\n",
    "sel = Selector(text=html)\n",
    "\n",
    "#I'm extracting the price data of the books in the website \n",
    "prices_of_books = sel.xpath('//p[@class=\"price_color\"]/text()').extract()\n",
    "\n",
    "print(\"Book Price:\")\n",
    "for pricing in prices_of_books:\n",
    "    print(pricing.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de85bb73-87e3-4e26-9a85-00420b5ae67c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book ratings in terms of star numbers:\n",
      "Three\n",
      "One\n",
      "One\n",
      "Four\n",
      "Five\n",
      "One\n",
      "Four\n",
      "Three\n",
      "Four\n",
      "One\n",
      "Two\n",
      "Four\n",
      "Five\n",
      "Five\n",
      "Five\n",
      "Three\n",
      "One\n",
      "One\n",
      "Two\n",
      "Two\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scrapy import Selector\n",
    "import requests\n",
    "\n",
    "def rating_of_books(url):\n",
    "    \n",
    "    html = requests.get(url).content\n",
    "    \n",
    "    \n",
    "    sel = Selector(text=html)\n",
    "    \n",
    "   #I'm extracting the rating of the books in the website  \n",
    "    bookratings = sel.xpath('//p[contains(@class, \"star-rating\")]/@class').extract()\n",
    "    \n",
    "   \n",
    "    cleanedbookratings = [rating.replace('star-rating ', '') for rating in bookratings]\n",
    "    \n",
    "   \n",
    "    print(\"book ratings in terms of star numbers:\")\n",
    "    for rating_in_website in cleanedbookratings:\n",
    "        print(rating_in_website)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://books.toscrape.com/'\n",
    "    rating_of_books(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b3c2f97-b3cf-444f-940e-0b4da4734d29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book names:\n",
      "A Light in the Attic\n",
      "Tipping the Velvet\n",
      "Soumission\n",
      "Sharp Objects\n",
      "Sapiens: A Brief History of Humankind\n",
      "The Requiem Red\n",
      "The Dirty Little Secrets of Getting Your Dream Job\n",
      "The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull\n",
      "The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics\n",
      "The Black Maria\n",
      "Starving Hearts (Triangular Trade Trilogy, #1)\n",
      "Shakespeare's Sonnets\n",
      "Set Me Free\n",
      "Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\n",
      "Rip it Up and Start Again\n",
      "Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991\n",
      "Olio\n",
      "Mesaerion: The Best Science Fiction Stories 1800-1849\n",
      "Libertarianism for Beginners\n",
      "It's Only the Himalayas\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scrapy import Selector\n",
    "import requests\n",
    "\n",
    "def name_of_books(url):\n",
    "    \n",
    "    html = requests.get(url).content\n",
    "    \n",
    "    \n",
    "    sel = Selector(text=html)\n",
    "    \n",
    "      #I'm extracting the names of the books in the website  \n",
    "    name_of_books = sel.xpath('//h3/a/@title').extract()\n",
    "    \n",
    "   \n",
    "    print(\"book names:\")\n",
    "    for bookname in name_of_books:\n",
    "        print(bookname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://books.toscrape.com/'\n",
    "    name_of_books(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e689c8d-d147-45c5-950c-2c626a3be654",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Situation:\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n",
      "\n",
      "In stock\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scrapy import Selector\n",
    "import requests\n",
    "\n",
    "def availability(url):\n",
    "   \n",
    "    html = requests.get(url).content\n",
    "    \n",
    "   \n",
    "    sel = Selector(text=html)\n",
    "    \n",
    "     #I'm extracting the availability of the books in the website in terms of whether they are in stock or not \n",
    "    bookavailability = sel.xpath('//p[@class=\"instock availability\"]/text()').extract()\n",
    "    \n",
    "    \n",
    "    print(\"Stock Situation:\")\n",
    "    for stock_situation in bookavailability:\n",
    "        print(stock_situation.strip())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://books.toscrape.com/'\n",
    "    availability(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c67211-aa2d-4fe4-b6bc-e7804b38f4a8",
   "metadata": {},
   "source": [
    "QUESTION 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "65699b18-ad7b-477a-926e-b288c0f74b78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book's Title: A Light in the Attic\n",
      "Price of the book: £51.77\n",
      "Rating of book in terms of star number: Three\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: Tipping the Velvet\n",
      "Price of the book: £53.74\n",
      "Rating of book in terms of star number: One\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: Soumission\n",
      "Price of the book: £50.10\n",
      "Rating of book in terms of star number: One\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: Sharp Objects\n",
      "Price of the book: £47.82\n",
      "Rating of book in terms of star number: Four\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: Sapiens: A Brief History of Humankind\n",
      "Price of the book: £54.23\n",
      "Rating of book in terms of star number: Five\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: The Requiem Red\n",
      "Price of the book: £22.65\n",
      "Rating of book in terms of star number: One\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: The Dirty Little Secrets of Getting Your Dream Job\n",
      "Price of the book: £33.34\n",
      "Rating of book in terms of star number: Four\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull\n",
      "Price of the book: £17.93\n",
      "Rating of book in terms of star number: Three\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics\n",
      "Price of the book: £22.60\n",
      "Rating of book in terms of star number: Four\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: The Black Maria\n",
      "Price of the book: £52.15\n",
      "Rating of book in terms of star number: One\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: Starving Hearts (Triangular Trade Trilogy, #1)\n",
      "Price of the book: £13.99\n",
      "Rating of book in terms of star number: Two\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: Shakespeare's Sonnets\n",
      "Price of the book: £20.66\n",
      "Rating of book in terms of star number: Four\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: Set Me Free\n",
      "Price of the book: £17.46\n",
      "Rating of book in terms of star number: Five\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\n",
      "Price of the book: £52.29\n",
      "Rating of book in terms of star number: Five\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: Rip it Up and Start Again\n",
      "Price of the book: £35.02\n",
      "Rating of book in terms of star number: Five\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991\n",
      "Price of the book: £57.25\n",
      "Rating of book in terms of star number: Three\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: Olio\n",
      "Price of the book: £23.88\n",
      "Rating of book in terms of star number: One\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: Mesaerion: The Best Science Fiction Stories 1800-1849\n",
      "Price of the book: £37.59\n",
      "Rating of book in terms of star number: One\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: Libertarianism for Beginners\n",
      "Price of the book: £51.33\n",
      "Rating of book in terms of star number: Two\n",
      "available in the stock \n",
      "==================================================\n",
      "Book's Title: It's Only the Himalayas\n",
      "Price of the book: £45.17\n",
      "Rating of book in terms of star number: Two\n",
      "available in the stock \n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scrapy import Selector\n",
    "import requests\n",
    "\n",
    "def website(url):\n",
    "    \n",
    "    html = requests.get(url).content\n",
    "    \n",
    "    \n",
    "    sel = Selector(text=html)\n",
    "    \n",
    "    \n",
    "    books_in_website = []\n",
    "    book_information = sel.xpath('//article[@class=\"product_pod\"]')\n",
    "    \n",
    "    for info in book_information:\n",
    "        book_data = {}\n",
    "        book_data['book_name'] = info.xpath('h3/a/@title').extract_first()\n",
    "        book_data['pricing'] = info.xpath('div/p[@class=\"price_color\"]/text()').extract_first()\n",
    "        book_data['rating_stars'] = info.xpath('p/@class').re_first(r'star-rating (\\w+)')\n",
    "        book_data['description_of_book'] = info.xpath('p[@class=\"excerpt\"]/text()').extract_first()\n",
    "        book_data['availability_of_book'] = info.xpath('div/p[@class=\"instock availability\"]/text()').extract_first()\n",
    "        \n",
    "     \n",
    "        if book_data['pricing']:\n",
    "            book_data['pricing'] = book_data['pricing'].strip()\n",
    "        if book_data['rating_stars']:\n",
    "            book_data['rating_stars'] = book_data['rating_stars'].strip()\n",
    "        if book_data['availability_of_book']:\n",
    "            book_data['availability_of_book'] = book_data['availability_of_book'].strip()\n",
    "        \n",
    "        books_in_website.append(book_data)\n",
    "    \n",
    "    return books_in_website\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://books.toscrape.com/'\n",
    "    data = website(url)\n",
    "    \n",
    "  \n",
    "    for book_data in data:\n",
    "        print(\"Book's Title:\", book_data['book_name'])\n",
    "        print(\"Price of the book:\", book_data['pricing'])\n",
    "        print(\"Rating of book in terms of star number:\", book_data['rating_stars'])\n",
    "        print(\"available in the stock\", book_data['availability_of_book'])\n",
    "        print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751e5bdf-ede2-4ea6-9516-53d720c5bfd8",
   "metadata": {},
   "source": [
    "organized the data in a way that shows the particular book with its name, price, rating and stock information at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ab1459e-deaa-4d0a-a9f8-b96d04bd2017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scrapy import Selector\n",
    "import requests\n",
    "\n",
    "def website(url):\n",
    "    html = requests.get(url).content\n",
    "    sel = Selector(text=html)\n",
    "    \n",
    "    books_in_website = []\n",
    "    book_information = sel.xpath('//article[@class=\"product_pod\"]')\n",
    "    \n",
    "    for info in book_information:\n",
    "        book_data = {}\n",
    "        book_data['book_name'] = info.xpath('h3/a/@title').extract_first()\n",
    "        book_data['pricing'] = info.xpath('div/p[@class=\"price_color\"]/text()').extract_first()\n",
    "        book_data['rating_stars'] = info.xpath('p/@class').re_first(r'star-rating (\\w+)')\n",
    "        book_data['description_of_book'] = info.xpath('p[@class=\"excerpt\"]/text()').extract_first()\n",
    "        book_data['availability_of_book'] = info.xpath('div/p[@class=\"instock availability\"]/text()').extract_first()\n",
    "        \n",
    "        if book_data['pricing']:\n",
    "            book_data['pricing'] = book_data['pricing'].strip()\n",
    "        if book_data['rating_stars']:\n",
    "            book_data['rating_stars'] = book_data['rating_stars'].strip()\n",
    "        if book_data['availability_of_book']:\n",
    "            book_data['availability_of_book'] = book_data['availability_of_book'].strip()\n",
    "        \n",
    "     \n",
    "        if book_data['availability_of_book'] and \"in stock\" in book_data['availability_of_book'].lower():\n",
    "            books_in_website.append(book_data)\n",
    "    \n",
    "    return books_in_website\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://books.toscrape.com/'\n",
    "    data = website(url)\n",
    "    \n",
    "    for book_data in data:\n",
    "        print(\"Book's Title:\", book_data['book_name'])\n",
    "        print(\"Price of the book:\", book_data['pricing'])\n",
    "        print(\"Rating of book in terms of star number:\", book_data['rating_stars'])\n",
    "        print(\"Available in the stock:\", book_data['availability_of_book'])\n",
    "        print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c935ec-86a7-4bac-af97-507b41b722d1",
   "metadata": {},
   "source": [
    "above, since there wasn't any missing values or inconsistencies in the data, I tried to do a clean up based on books not being available in the market so that their info can be deleted. To do that, my code checks if the book is still present in the stock before adding it to my list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfcd53b-5e34-45c9-ad44-b1c8d68a78c1",
   "metadata": {},
   "source": [
    "QUESTION 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c04b7d83-21ea-403e-9d36-d734e9884c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dilagurer/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8583f9f1-3c79-473b-a673-5d6d42cd0a37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your data has been saved to the file 'data.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scrapy import Selector\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def website(url):\n",
    "   \n",
    "    html = requests.get(url).content\n",
    "    \n",
    "    \n",
    "    sel = Selector(text=html)\n",
    "    \n",
    "  \n",
    "    books_list = []\n",
    "    book_information = sel.xpath('//article[@class=\"product_pod\"]')\n",
    "    \n",
    "    for info in book_information:\n",
    "        b = {}\n",
    "        \n",
    "     \n",
    "        bookname = info.xpath('h3/a/@title').extract_first()\n",
    "        if bookname:\n",
    "            b['book_name'] = bookname.strip()\n",
    "        else:\n",
    "            b['book_name'] = \"No Title Available\"\n",
    "        \n",
    "       \n",
    "        pricing = info.xpath('div/p[@class=\"price_color\"]/text()').extract_first()\n",
    "        if pricing:\n",
    "            pricing = pricing.strip().replace('£', '')\n",
    "            try:\n",
    "                b['pricing_book'] = float(pricing)\n",
    "            except ValueError:\n",
    "                print(\" price format is invalid for the particular book named\", b['book_name'])\n",
    "                b['pricing_book'] = None\n",
    "        else:\n",
    "            print(\"price is not available for book named\", b['book_name'])\n",
    "            b['pricing'] = None\n",
    "        \n",
    "       \n",
    "        rating_stars = info.xpath('p/@class').re_first(r'star-rating (\\w+)')\n",
    "        if rating_stars:\n",
    "            b['rating_of_book'] = rating_stars.strip()\n",
    "        else:\n",
    "            print(\"rating is not available for book named\", b['book_name'])\n",
    "            b['rating_of_book'] = \"No info for rating\"\n",
    "        \n",
    "       \n",
    "        availability_stock = info.xpath('div/p[@class=\"instock availability\"]/text()').extract_first()\n",
    "        if availability_stock:\n",
    "            b['avail'] = availability_stock.strip()\n",
    "        else:\n",
    "            print(\"Availability is not indicated for book named\", b['book_name'])\n",
    "            b['avail'] = \"no info\"\n",
    "        \n",
    "        books_list.append(b)\n",
    "    \n",
    "    return books_list\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://books.toscrape.com/'\n",
    "    books_data = website(url)\n",
    "    \n",
    "   \n",
    "    df = pd.DataFrame(books_data)\n",
    "    \n",
    "\n",
    "    df.to_csv('data.csv', index=False)\n",
    "    \n",
    "    print(\"your data has been saved to the file 'data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1c0fb9-adeb-49fe-974b-6dfc307fb0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
